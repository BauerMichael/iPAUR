\relax 
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\@writefile{lol}{\select@language{english}}
\citation{Canny}
\citation{Mumford-et-al-cpam}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Chambolle10afirst-order}
\citation{ROF}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:introduction}{{1}{2}}
\citation{Bredies}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Basic Concepts}{4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:basic_concepts}{{2}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Images in Mathematics}{4}}
\newlabel{sec:images_in_mathematics}{{2.1}{4}}
\newlabel{def:image}{{2.1}{4}}
\newlabel{rem:continuous_vs_discrete}{{2.2}{4}}
\citation{Nocedal-Wright}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Mapping of images.}}{5}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:image_mapping}{{2.1}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Convex Optimization and Convex Analysis}{5}}
\newlabel{sec:convex_optimization_and_convex_analysis}{{2.2}{5}}
\newlabel{eq:optimization_problem_original}{{2.1}{5}}
\newlabel{def:active_set}{{2.3}{5}}
\citation{Nocedal-Wright}
\citation{Chambolle-et-al-10}
\citation{Rockafellar}
\newlabel{def:licq}{{2.4}{6}}
\newlabel{the:kkt_conditions}{{2.5}{6}}
\newlabel{eq:stationarity}{{2.2a}{6}}
\newlabel{eq:complementary_conditions}{{2.2e}{6}}
\newlabel{eq:kkt_conditions}{{2.2}{6}}
\newlabel{def:convex_set}{{2.7}{7}}
\newlabel{ex:convex_set}{{2.8}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Examples of convex sets.}}{7}}
\newlabel{fig:convex_and_non_convex_sets}{{2.2}{7}}
\newlabel{def:indicator_function}{{2.9}{7}}
\citation{Rockafellar}
\newlabel{def:convex_function_proper_lower_semicontinuous}{{2.10}{8}}
\newlabel{eq:convex_function}{{2.3}{8}}
\newlabel{eq:lsc_example}{{2.4}{8}}
\newlabel{rem:concave_function}{{2.12}{8}}
\newlabel{ex:convex_function}{{2.13}{8}}
\newlabel{def:domain_epigraph}{{2.14}{9}}
\newlabel{def:convex_function_else}{{2.15}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Example of a convex and a l.s.c. function.}}{10}}
\newlabel{fig:convex_function}{{2.3}{10}}
\newlabel{ex:convex_function_reloaded}{{2.16}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Domain and Epigraph.}}{10}}
\newlabel{fig:domain_epigraph}{{2.4}{10}}
\citation{Rockafellar}
\newlabel{def:legendre_fenchel_conjugate}{{2.17}{11}}
\newlabel{eq:legendre_fenchel_conjugate}{{2.5}{11}}
\newlabel{ex:legendre_fenchel_conjugate_example}{{2.20}{11}}
\citation{Rockafellar}
\newlabel{def:subgradient_subdifferential}{{2.21}{13}}
\newlabel{eq:subgradient}{{2.6}{13}}
\newlabel{ex:subgradient_subdifferential}{{2.23}{13}}
\citation{Chambolle-et-al-10}
\citation{Rockafellar}
\newlabel{prop:zero_element_of_subgradient}{{2.24}{14}}
\newlabel{prop:global_minimum}{{2.25}{14}}
\citation{Rockafellar}
\newlabel{def:projection_operator}{{2.26}{15}}
\newlabel{eq:proximity_operator}{{2.8}{15}}
\newlabel{the:moreau_identity}{{2.27}{15}}
\newlabel{eq:equivalence_of_moreau_property}{{2.9}{15}}
\newlabel{eq:prox_z}{{2.10}{15}}
\newlabel{eq:proximity_operator_reloaded}{{2.11}{15}}
\citation{Chambolle-et-al-10}
\citation{Jitkomut}
\citation{Giusti}
\newlabel{eq:moreau_identity_reloaded}{{2.12}{16}}
\newlabel{ex:projection_operator}{{2.29}{16}}
\citation{Chambolle-et-al-10}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Total Variation}{17}}
\newlabel{sec:total_variation}{{2.3}{17}}
\newlabel{def:total_variation}{{2.30}{17}}
\newlabel{prop:u_is_smooth}{{2.31}{17}}
\newlabel{eq:nabla_equals_minus_divergence}{{2.13}{17}}
\newlabel{eq:tvl1}{{2.14}{17}}
\citation{Giusti}
\citation{Giusti}
\citation{Chambolle-et-al-10}
\citation{Pock-et-al-iccv09}
\newlabel{def:variation_of_a_function}{{2.33}{18}}
\newlabel{ex:total_variation_one_d}{{2.34}{18}}
\newlabel{def:functions_of_bounded_variation}{{2.35}{18}}
\citation{Chambolle-et-al-10}
\citation{Chambolle10afirst-order}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}The ROF, TVL1 and Mumford-Shah Functional}{20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:the_rof_tvl1_and_mumford_shah_functional}{{3}{20}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The General Saddle-Point Problem}{20}}
\newlabel{sec:the_general_saddle_point_problem}{{3.1}{20}}
\newlabel{eq:the_saddle_point_problem}{{3.1}{20}}
\citation{Zeidler}
\citation{Chambolle-et-al-10}
\citation{Arrow-Hurwicz}
\citation{Appleton-Talbot}
\newlabel{eq:primal_problem}{{3.2}{21}}
\newlabel{eq:dual_problem}{{3.3}{21}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}A Primal-Dual Algorithm}{21}}
\newlabel{sec:a_firs_order_primal_dual_algorithm}{{3.2}{21}}
\citation{Zhu-Chan}
\citation{Pock-et-al-iccv09}
\citation{Chambolle10afirst-order}
\citation{Chambolle10afirst-order}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Chambolle10afirst-order}
\citation{Chambolle10afirst-order}
\citation{Pock2011}
\citation{Chambolle10afirst-order}
\newlabel{alg:primal_dual_algorithm}{{3.1}{22}}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Chambolle10afirst-order}
\newlabel{alg:realtime_primal_dual_algorithm}{{3.3}{23}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Discrete Setting}{23}}
\newlabel{sec:discrete_setting}{{3.3}{23}}
\newlabel{eq:pixel_grid}{{3.4}{23}}
\newlabel{eq:inner_product}{{3.5}{23}}
\newlabel{eq:inner_product_space_y}{{3.6}{24}}
\newlabel{def:discrete_gradient_operator}{{3.4}{24}}
\newlabel{def:discrete_divergence_operator}{{3.5}{24}}
\citation{Chambolle10afirst-order}
\citation{ROF}
\newlabel{prop:bound_on_the_norm}{{3.6}{25}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}The ROF Model}{26}}
\newlabel{sec:the_rof_model}{{3.4}{26}}
\newlabel{def:the_rof_functional}{{3.7}{26}}
\newlabel{eq:the_rof_model}{{3.7}{26}}
\newlabel{eq:discrete_rof_model}{{3.8}{26}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.1}ROF Model as Saddle-Point Problem}{26}}
\newlabel{sub:rof_model_as_saddle_point_problem}{{3.4.1}{26}}
\newlabel{eq:primal_rof_problem}{{3.9}{26}}
\newlabel{eq:the_set_P}{{3.10}{27}}
\newlabel{eq:primal_dual_rof_problem}{{3.11}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.2}The Proximity Operators of the ROF Model}{27}}
\newlabel{sub:the_proximity_operators_for_the_rof_model}{{3.4.2}{27}}
\citation{Chambolle10afirst-order}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces Pointwise $l2$ projections.}}{28}}
\newlabel{fig:pointwise_l2_projections}{{3.1}{28}}
\citation{Strekalovskiy-Cremers-eccv14}
\newlabel{eq:proximity_operator_g_rof}{{3.12}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4.3}Stopping Criterion}{29}}
\newlabel{sub:stopping_criterion_rof}{{3.4.3}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}The TVL1 Model}{29}}
\newlabel{sec:the_tvl1_model}{{3.5}{29}}
\newlabel{def:tvl1_functional}{{3.8}{29}}
\newlabel{eq:primal_formulation_tvl1}{{3.14}{30}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5.1}TVL1 as Saddle-Point Problem}{30}}
\newlabel{sub:tvl1_as_saddle_point_problem}{{3.5.1}{30}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline The Proximity Operators of the TVL1 Model}{31}}
\newlabel{ssub:the_proximity_operators_of_the_tvl1_model}{{3.5.1}{31}}
\newlabel{eq:prox_g_tvl1}{{3.15}{32}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}The Mumford-Shah Model}{32}}
\newlabel{sec:the_mumford_shah_model}{{3.6}{32}}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\newlabel{def:the_mumford_shah_functional}{{3.9}{33}}
\newlabel{eq:the_mumford_shah_functional}{{3.9}{33}}
\newlabel{eq:ms_regularizer}{{3.17}{33}}
\newlabel{eq:edge_set_k}{{3.19}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.1}Mumford-Shah as Saddle-Point Problem}{34}}
\newlabel{sub:mumford_shah_as_saddle_point_problem}{{3.6.1}{34}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6.2}The Proximity Operators of the Mumford-Shah Model}{35}}
\newlabel{sub:the_proximity_operators_of_the_mumford_shah_model}{{3.6.2}{35}}
\newlabel{eq:moreau_mumford_shah_regularizer}{{3.20}{36}}
\newlabel{eq:partial_r}{{3.21}{36}}
\newlabel{eq:bound_on_p}{{3.22}{37}}
\newlabel{eq:minimal_energy}{{3.23}{37}}
\newlabel{eq:proximity_operator_R}{{3.24}{37}}
\citation{Strekalovskiy-Cremers-eccv14}
\newlabel{eq:proximity_operator_r_star}{{3.25}{38}}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Plot of a objective function within a minimum function.}}{39}}
\newlabel{fig:objective_function}{{3.2}{39}}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Minimizing the Mumford-Shah Functional}{40}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:minimizing_the_mumford_shah_functional}{{4}{40}}
\newlabel{def:the_mumford_shah_functional_revisited}{{4.1}{40}}
\newlabel{eq:the_mumford_shah_functional_revisited}{{4.1}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Convex Relaxation}{40}}
\newlabel{sec:convex_relaxation}{{4.1}{40}}
\newlabel{def:characteristic_function}{{4.2}{40}}
\newlabel{eq:characteristic_function}{{4.2}{40}}
\citation{Alberti-et-al-lnss}
\citation{Alberti-et-al-cvpde}
\citation{Pock-et-al-iccv09}
\citation{Alberti-et-al-lnss}
\citation{Alberti-et-al-cvpde}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Characteristic Function of a SBV function.}}{41}}
\newlabel{fig:characteristic_function}{{4.1}{41}}
\newlabel{convex_relaxation_of_the_mumford_shah_functional}{{4.3}{41}}
\newlabel{eq:convex_relaxed_ms}{{4.3}{41}}
\newlabel{eq:set_k_continuous}{{4.5}{41}}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\newlabel{eq:generic_functions}{{4.6}{42}}
\newlabel{eq:continous_saddle_point_problem}{{4.7}{42}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Discrete Setting}{42}}
\newlabel{sec:discrete_setting_ms}{{4.2}{42}}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\newlabel{eq:mumford_shah_saddle_point_problem}{{4.8}{43}}
\newlabel{eq:local_constraint}{{4.10}{43}}
\newlabel{eq:non_local_constraint}{{4.11}{43}}
\citation{Pock-et-al-iccv09}
\newlabel{def:discrete_gradient_operator_ms}{{4.6}{44}}
\newlabel{def:discrete_divergence_operator_ms}{{4.7}{44}}
\newlabel{prop:bound_on_the_norm_ms}{{4.8}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Projection onto the sets $\boldsymbol  {C}$ and $\boldsymbol  {K}$}{44}}
\newlabel{sec:projection_onto_the_sets_C_and_K}{{4.3}{44}}
\newlabel{alg:primal_dual_cremers}{{4.9}{45}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}Projection onto $\boldsymbol  {C}$}{45}}
\newlabel{eq:clipping}{{4.13}{45}}
\newlabel{rem:clipping}{{4.11}{45}}
\citation{dykstra-et-al-aors14}
\citation{dykstra-et-al-aors14}
\citation{Cremers-Kolev-pami11}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Clipping on a set.}}{46}}
\newlabel{fig:projection_onto_c}{{4.2}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}The projection onto $\boldsymbol  {K}$}{46}}
\newlabel{sub:the_projection_onto_K}{{4.3.2}{46}}
\newlabel{alg:dykstra}{{4.12}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Dykstra's iteration scheme.}}{47}}
\newlabel{fig:dykstra}{{4.3}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}Decomposition of $\boldsymbol  {K}$}{47}}
\newlabel{sub:decomposition_of_K}{{4.3.3}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Projection onto $\boldsymbol  {K_{p}}$}{47}}
\newlabel{eq:linearSystem}{{4.14}{48}}
\newlabel{eq:1stequ}{{4.15}{48}}
\newlabel{eq:2ndequ}{{4.16}{48}}
\citation{Chambolle-et-al-10}
\newlabel{eq:tmp1}{{4.17}{49}}
\citation{kelvey-ajp}
\citation{kelvey-ajp}
\citation{strekalovskiy-et-al-siims14}
\newlabel{eq:cubic}{{4.18}{50}}
\newlabel{alg:projection_on_parabola}{{4.13}{50}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Projection onto $K_{nl}$}{51}}
\newlabel{sub:projection_onto_K_nl}{{4.3.5}{51}}
\newlabel{eq:equalityConstraint}{{4.19a}{51}}
\newlabel{eq:inequalityConstraint}{{4.19b}{51}}
\newlabel{eq:optimization_problem}{{4.19}{51}}
\newlabel{alg:softshrinkage}{{4.14}{51}}
\newlabel{eq:softshrinkage}{{4.20}{52}}
\newlabel{prop:softshrinkage}{{4.15}{52}}
\newlabel{eq:long_formula}{{4.21}{53}}
\newlabel{eq:short_formula}{{4.22}{53}}
\citation{Boyd}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}An Alternative Approach using Lagrange Multiplier}{55}}
\newlabel{sec:an_alternative_approach_using_lagrangre_multipliers}{{4.4}{55}}
\newlabel{eq:original_saddle_point_problem}{{4.23}{56}}
\newlabel{eq:non_local_constraint_reloaded}{{4.24}{56}}
\newlabel{eq:lagrangian}{{4.25}{56}}
\newlabel{prop:equivalence_of_two_problems}{{4.16}{56}}
\newlabel{eq:lagrange_saddle_point_problem}{{4.26}{56}}
\newlabel{eq:equality_of_problems}{{4.27}{56}}
\newlabel{eq:before_cases}{{4.28}{57}}
\newlabel{eq:cases}{{4.29}{57}}
\newlabel{alg:mumford_shah_lagrange_multiplier}{{4.17}{59}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Computing the 0.5-Isosurface}{59}}
\newlabel{sec:computing_the_0_5_isosurface}{{4.5}{59}}
\citation{Pock-et-al-iccv09}
\newlabel{alg:0.5_isosurface}{{4.19}{60}}
\@writefile{toc}{\contentsline {section}{\numberline {4.6}Convergence Criterion}{60}}
\newlabel{sec:convergence_criterion}{{4.6}{60}}
\citation{CUDA}
\citation{OpenCV}
\citation{Bauer}
\citation{Pock-et-al-iccv09}
\citation{FastMS}
\citation{Strekalovskiy-Cremers-eccv14}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Applications to Imaging}{61}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:applications_to_imaging}{{5}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}General Setting}{61}}
\newlabel{sec:general_setting}{{5.1}{61}}
\citation{Bredies}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Images used in Chapter 5}}{62}}
\newlabel{fig:images_used}{{5.1}{62}}
\citation{Bredies}
\citation{CPlusPlus}
\newlabel{eq:mse}{{5.1}{63}}
\newlabel{eq:psnr}{{5.2}{63}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Linearized Storage of Images}{63}}
\newlabel{sec:linearized_storage_of_images}{{5.2}{63}}
\newlabel{eq:color_pixel_grid}{{5.3}{64}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Image Approximation using the ROF Model}{64}}
\newlabel{sec:image_approximation_using_the_rof_model}{{5.3}{64}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.1}Implementation Issues}{64}}
\newlabel{sub:implementation_issues}{{5.3.1}{64}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Computing $p^{n+1} = (\textnormal  {Id} + \sigma \tmspace  +\thinmuskip {.1667em}\partial \tmspace  +\thinmuskip {.1667em}F^{\ast })^{-1}(p^{n} + \sigma \tmspace  +\thinmuskip {.1667em}\nabla \mathaccentV {bar}016{u}^{n})$}{65}}
\newlabel{sub:computing_p}{{5.3.1}{65}}
\@writefile{toc}{\contentsline {subsubsection}{\nonumberline Computing $u^{n+1} = (\textnormal  {Id} - \tau \tmspace  +\thinmuskip {.1667em}\partial \tmspace  +\thinmuskip {.1667em}G)^{-1}(u^{n} + \tau \tmspace  +\thinmuskip {.1667em}\nabla ^{T}p^{n+1})$}{66}}
\newlabel{sub:computing_u}{{5.3.1}{66}}
\citation{Chambolle10afirst-order}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.2}Estimation of $\boldsymbol  {\lambda }$}{68}}
\newlabel{sub:estimation_of_lambda_rof}{{5.3.2}{68}}
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Overview of values for $\lambda $ in the ROF model.}}{69}}
\newlabel{tab:estimation_of_lambda_rof}{{5.1}{69}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces First estimate of $\lambda $ for the ROF model.}}{69}}
\newlabel{fig:estimation_of_lambda_rof}{{5.2}{69}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3.3}Estimation of $\boldsymbol  {\tau }$}{69}}
\newlabel{sub:estimation_of_tau_rof}{{5.3.3}{69}}
\@writefile{lot}{\contentsline {table}{\numberline {5.2}{\ignorespaces Best estimate of $\tau $ for the ROF model.}}{70}}
\newlabel{tab:estimation_of_tau_rof}{{5.2}{70}}
\@writefile{lot}{\contentsline {table}{\numberline {5.3}{\ignorespaces Run-times for best parameters in ROF model.}}{70}}
\newlabel{tab:rof_cpu_vs_gpu}{{5.3}{70}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Image Approximation using the TVL1 Model}{71}}
\newlabel{sec:image_approximation_using_the_tvl1_model}{{5.4}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Estimation of $\boldsymbol  {\lambda }$}{72}}
\newlabel{sub:estimation_of_lambda_tvl1}{{5.4.1}{72}}
\@writefile{lot}{\contentsline {table}{\numberline {5.4}{\ignorespaces Best estimate of $\lambda $ for the TVL1 model.}}{72}}
\newlabel{tab:estimation_of_lambda_tvl1}{{5.4}{72}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Estimation of $\boldsymbol  {\tau }$}{72}}
\newlabel{sub:estimation_of_tau_tvl1}{{5.4.2}{72}}
\@writefile{lot}{\contentsline {table}{\numberline {5.5}{\ignorespaces Run-times for best parameters in TVL1 model.}}{73}}
\newlabel{tab:tvl1_cpu_vs_gpu}{{5.5}{73}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Best approximation using the TVL1 model with Landscape image.}}{73}}
\newlabel{fig:best_tvl1_landscape}{{5.3}{73}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Image Approximation using the Real-Time Minimizer}{73}}
\newlabel{sec:image_approximation_using_the_real_time_minimizer}{{5.5}{73}}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Estimation of $\boldsymbol  {\lambda }$ and $\boldsymbol  {\nu }$}{75}}
\newlabel{sub:estimation_of_lambda_and_nu_rt}{{5.5.1}{75}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Comparing Audrey Hepburn pwc. and pws. using real-time Mumford-Shah model.}}{76}}
\newlabel{fig:estimation_of_lambda_and_nu_rt}{{5.4}{76}}
\citation{Strekalovskiy-Cremers-eccv14}
\citation{Strekalovskiy-Cremers-eccv14}
\@writefile{lot}{\contentsline {table}{\numberline {5.6}{\ignorespaces Run-Times for best parameters real-time framework.}}{77}}
\newlabel{tab:realtime_cpu_vs_gpu}{{5.6}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}Image Cartooning}{77}}
\newlabel{sec:image_cartooning}{{5.6}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6.1}Edge Highlighting}{77}}
\newlabel{sub:edge_highlighting}{{5.6.1}{77}}
\newlabel{eq:first_inequality}{{5.4}{77}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Cartooning example of Audrey Hepburn and Landscape image.}}{78}}
\newlabel{fig:cartooning_hepburn_and_landscaperealtime}{{5.5}{78}}
\citation{Bauer}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}Image Denoising}{79}}
\newlabel{sec:image_denoising}{{5.7}{79}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.1}Gaussian Noise}{80}}
\newlabel{sub:gaussian_noise}{{5.7.1}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Removing Gaussian noise using the ROF, TVL1 and real-time Mumford-Shah framework.}}{80}}
\newlabel{fig:denoising_lena_gauss}{{5.6}{80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7.2}Salt and Pepper Noise}{80}}
\newlabel{sub:salt_and_pepper_noise}{{5.7.2}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Salt and pepper denoising example: ROF.}}{81}}
\newlabel{fig:denoising_lena_rof_sap}{{5.7}{81}}
\@writefile{lot}{\contentsline {table}{\numberline {5.7}{\ignorespaces Best estimate of $\tau $ for the TVL1 model for denoising.}}{81}}
\newlabel{tab:estimation_of_tau_denoising}{{5.7}{81}}
\@writefile{toc}{\contentsline {section}{\numberline {5.8}Image Inpainting}{81}}
\newlabel{sec:image_inpainting}{{5.8}{81}}
\citation{Chambolle10afirst-order}
\@writefile{lof}{\contentsline {figure}{\numberline {5.8}{\ignorespaces Salt and pepper denoising example: TVL1.}}{82}}
\newlabel{fig:denoising_lena_tvl1_sap}{{5.8}{82}}
\newlabel{eq:inpainting_model}{{5.5}{82}}
\newlabel{eq:inpainting_primal_dual}{{5.6}{82}}
\newlabel{eq:proximity_operator_f_star_inpainting}{{5.7}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.9}{\ignorespaces Inpainting with seventy percent data loss with denoising.}}{83}}
\newlabel{fig:inpainting_lena_rof}{{5.9}{83}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.10}{\ignorespaces Inpainting with seventy percent data loss without denoising.}}{84}}
\newlabel{fig:inpainting_lena_rof_pwc}{{5.10}{84}}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\citation{Pock-et-al-iccv09}
\@writefile{lot}{\contentsline {table}{\numberline {5.8}{\ignorespaces Best estimate of $\tau $ for image inpainting.}}{85}}
\newlabel{tab:best_tau_inpaint}{{5.8}{85}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.11}{\ignorespaces Unsuccessful inpainting process with small $\tau $.}}{85}}
\newlabel{fig:unsuccessful_inpainting}{{5.11}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {5.9}Minimizing the Mumford-Shah Functional}{86}}
\newlabel{sec:minimizing_the_mumford_shah_functional}{{5.9}{86}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.1}Best $\lambda $ and $\nu $ estimation}{86}}
\newlabel{sub:best_lambda_and_nu_estimation}{{5.9.1}{86}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.12}{\ignorespaces Parameter estimation for the convex relaxed Mumford-Shah functional.}}{86}}
\newlabel{fig:best_parameter_estimation_cr}{{5.12}{86}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.13}{\ignorespaces La Dama image approximation with convex relaxed Mumford-Shah.}}{87}}
\newlabel{fig:ladama_ms_compare}{{5.13}{87}}
\@writefile{lot}{\contentsline {table}{\numberline {5.9}{\ignorespaces Run-Time comparison: Lagrange vs. Dykstra.}}{87}}
\newlabel{tab:run_time_compare_lagrange_vs_dykstra}{{5.9}{87}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.2}Denoising with the Mumford-Shah Functional}{87}}
\newlabel{sub:denoising_with_the_mumford_shah_functional}{{5.9.2}{87}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.14}{\ignorespaces Removing Gaussian noise with convex relaxed Mumford-Shah.}}{88}}
\newlabel{fig:synth_gauss_ms_compare}{{5.14}{88}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.15}{\ignorespaces Mumford-Shah approximation of Lena using 29 level.}}{88}}
\newlabel{fig:lena_ms}{{5.15}{88}}
\citation{FastMS}
\citation{Strekalovskiy-Cremers-eccv14}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.3}Denoising Comparison}{89}}
\newlabel{sub:denoising_comparison}{{5.9.3}{89}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.16}{\ignorespaces Removing Gaussian noise: comparison of several models.}}{89}}
\newlabel{fig:synth_gauss_compare}{{5.16}{89}}
\citation{Keating}
\@writefile{lof}{\contentsline {figure}{\numberline {5.17}{\ignorespaces Gauss denoising comparison of several models with zooming into images.}}{90}}
\newlabel{fig:synth_gauss_compare_zoomed}{{5.17}{90}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.9.4}Image Segmentation}{90}}
\newlabel{sub:image_segmentation}{{5.9.4}{90}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.18}{\ignorespaces Example images for segmentation.}}{90}}
\newlabel{fig:example_images_segmentation}{{5.18}{90}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.19}{\ignorespaces Evolution process for image segmentation with real-time Mumford-Shah.}}{91}}
\newlabel{fig:segmentation_evolution_test_images_rt}{{5.19}{91}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.20}{\ignorespaces Evolution process for image segmentation with Lagrange Mumford-Shah.}}{92}}
\newlabel{fig:segmentation_evolution_test_images_cr}{{5.20}{92}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.21}{\ignorespaces Image segmentation for a brain tumor image.}}{93}}
\newlabel{fig:segmentation_evolution_keating}{{5.21}{93}}
\bibstyle{plain}
\bibdata{bibliography}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Conclusion}{94}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lol}{\addvspace {10\p@ }}
\newlabel{cha:conclusion}{{6}{94}}
\bibcite{Alberti-et-al-lnss}{1}
\bibcite{Alberti-et-al-cvpde}{2}
\bibcite{Chambolle10afirst-order}{3}
\bibcite{Appleton-Talbot}{4}
\bibcite{Arrow-Hurwicz}{5}
\bibcite{Bauer}{6}
\bibcite{Boyd}{7}
\bibcite{dykstra-et-al-aors14}{8}
\bibcite{Bredies}{9}
\bibcite{Canny}{10}
\bibcite{Chambolle-et-al-10}{11}
\bibcite{Cremers-Kolev-pami11}{12}
\bibcite{Giusti}{13}
\bibcite{OpenCV}{14}
\bibcite{Keating}{15}
\bibcite{kelvey-ajp}{16}
\bibcite{Mumford-et-al-cpam}{17}
\bibcite{CPlusPlus}{18}
\bibcite{Nocedal-Wright}{19}
\bibcite{CUDA}{20}
\bibcite{Pock-et-al-iccv09}{21}
\bibcite{Rockafellar}{22}
\bibcite{ROF}{23}
\bibcite{Jitkomut}{24}
\bibcite{strekalovskiy-et-al-siims14}{25}
\bibcite{Strekalovskiy-Cremers-eccv14}{26}
\bibcite{FastMS}{27}
\bibcite{Pock2011}{28}
\bibcite{Zeidler}{29}
\bibcite{Zhu-Chan}{30}
