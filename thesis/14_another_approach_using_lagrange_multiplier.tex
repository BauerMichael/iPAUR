\section{An alternative approach} % (fold)
\label{sec:an_alternative_approach}
    
    In this section we present a formulation to solve the discrete Mumford-Shah Functional of subsection \ref{sub:the_mumford_shah_model_as_saddle_point_problem}. The idea is to decouple the set $K_{nl}$ to derive an alternative saddle-point problem, which can be solved with our primal-dual algorithm. Recalling the original problem, we had
        \begin{equation}
            \min_{u \in C} \max_{p \in K} \langle Au, p \rangle,
            \label{eq:standard_form}
        \end{equation}
    where we maximized over the whole set $K$, defined in equations \ref{eq:local_constraint} and \ref{eq:non_local_constraint}. As discussed in section \ref{sec:discrete_setting_ms}, this set is an intersection of several convex sets. We projected onto the non-local constraint, which was defined by
        $$
            K_{nl} = \left\{ \left| \sum_{k_{1} \le k \le k_{2}} p^{x}(i, j, k) \right| \le \nu \right\} \,\,\, \forall i, j, k_{1} \le k \le k_{2},
        $$
    where $p^{x}$ is defined as in subsection \ref{sub:decomposition_of_K}, using a soft-shrinkage scheme. This projection was used in each step of Dykstra's algorithm. We now want to solve this problem optimal by decoupling the non-local constraint. We note that in the following we drop the index representation for $p^{x}$. Instead of writting $p^{x}(i, j, k)$ we denote this by $p^{x}_{k}$ for a pair $(i,j)$ and all $k$. Decoupling means then, that we substitute $p^{x}_{k}$ by $s_{k_{1}, k_{2}}$ and introduce an additional constraint to take the bound on $\nu$ into account. We have
        \begin{equation}
            K_{nl} = \left\{ |s_{k_{1}, k_{2}}| \le \nu \,\,\, \textnormal{subject to} \,\,\, s_{k_{1}, k_{2}} = \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \right\}
            \label{eq:non_local_constraint_reloaded}
        \end{equation}
    for all combinations $1 \le k_{1} \le k \le k_{2} \le S$, $s_{k_{1}, k_{2}} \in \mathbb{R}^{2}$ and $s \in \mathbb{R}^{N \times M \times S \times 2}$, respectively. Alternatively, we can also denote this set by
        $$
            K_{nl} = \left\{ |s_{k_{1}, k_{2}}| \le \nu \,\,\, \textnormal{subject to} \,\,\, s_{k_{1}, k_{2}} - \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} = 0 \right\}
        $$
    We further present an auxiliary variable $\mu_{k_{1}, k_{2}} \in \mathbb{R}^{2}$, which belongs to a $\mu \in \mathbb{R}^{N \times M \times S \times 2}$. We define a new function
        \begin{equation}
            \mathcal{L}(u, \mu, p, s) = \langle Au, p \rangle + \sum_{k_{1} = 1}^{S} \sum_{k_{2} = k_{1}}^{S} \langle \mu_{k_{1}, k_{2}}, s_{k_{1}, k_{2}} - \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \rangle,
        \end{equation}
    in which we added to our original problem an enforced term corresponding to the constraint in $K_{nl}$. Taking now into account, that the constraint is an equality constraint, we have that all $\mu_{k_{1}, k_{2}}$ can either be greater, less than or equal to zero. Additionally, we need to be sure, that the inequality $|s_{k_{1}, k_{2}}| \le \nu$ holds. Then we obtain the following equivalence:
        $$
            \min_{u \in C} \max_{p \in K} \langle Au, p \rangle \Longleftrightarrow \min_{\substack{u \in C \\ \mu_{k_{1}, k_{2}}}} \max_{\substack{p \in K_{p} \\ |s_{k_{1}, k_{2}}| \le \nu}} \mathcal{L}(u, \mu, p, s),
        $$
    which complies to
        \begin{equation}
            \min_{u \in C} \max_{p \in K} \langle \nabla u, p \rangle \Longleftrightarrow \min_{\substack{u \in C \\ \mu_{k_{1}, k_{2}}}} \max_{\substack{p \in K_{p} \\ |s_{k_{1}, k_{2}}| \le \nu}} \langle \nabla u, p \rangle + \sum_{k_{1} = 1}^{S} \sum_{k_{2} = 1}^{S} \langle \mu_{k_{1}, k_{2}}, \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} - s_{k_{1}, k_{2}} \rangle,
            \label{eq:lagrange_problem}
        \end{equation}
    if we use $A = \nabla$ as in the other chapters. Let us proof this equivalence in the general case, where $A$ resemble a linear operator:

    \begin{proof}
        As we did not change either the properties on $u$ nor the set $C$, we assume for the rest of the proof, that we found an optimal value $u^{\ast}$. Further, assume we have a optimal value $s^{\ast}$, for which $|s^{\ast}_{k_{1}, k_{2}}| \le \nu$ for all possible combinations $(k_{1}, k_{2})$. Then, we do a case analysis:
        \begin{enumerate}
            \item If the equality
                $$
                    \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} - s^{\ast}_{k_{1}, k_{2}} = 0,
                $$
            holds, the saddle-point problem reduces to
                $$
                    \max_{p \in K_{p}} \langle Au^{\ast}, p \rangle.
                $$
            If the equality does not hold, we distinguish between two other cases:
            \item Let $\sum\limits_{k_{1} \le k \le k_{2}} p^{x}_{k} < s^{\ast}_{k_{1}, k_{2}}$, then first note, that this is equivalent to
                $$
                    \left|\left|\sum_{k_{1} \le k \le k_{2}} p^{x}_{k}\right|\right| < |s^{\ast}_{k_{1}, k_{2}}|.
                $$
            But as $|s^{\ast}_{k_{1}, k_{2}}| \le \nu$ we already have
                $$
                    \left|\left|\sum_{k_{1} \le k \le k_{2}} p^{x}_{k}\right|\right| \le \nu.
                $$
            Further, we obtain the minimal value over all possible $\mu_{k_{1}, k_{2}}$ in this case only if we let $\mu_{k_{1}, k_{2}} \longrightarrow \infty$, for which the whole energy becomes $-\infty$. Since, the conditions according to the set $K_{nl}$ are met and to avoid having a energy with the value $-\infty$, we set $\mu_{k_{1}, k_{2}} = 0$ in this case. We get again
                $$
                    \max_{p \in K_{p}} \langle Au^{\ast}, p \rangle.
                $$
            \item Now, let $\sum\limits_{k_{1} \le k \le k_{2}} p^{x}_{k} > s^{\ast}_{k_{1}, k_{2}}$. In this case we could again set $\mu_{k_{1}, k_{2}} = 0$. Then the last term in \ref{eq:lagrange_problem} will not be considered. But with this we are not able to tell anything about the sum over the $p^{x}_{k}$. We know that
                $$
                    \left|\left|\sum_{k_{1} \le k \le k_{2}} p^{x}_{k}\right|\right| > |s^{\ast}_{k_{1}, k_{2}}|
                $$
            and from our assumption that $|s^{\ast}_{k_{1}, k_{2}}| \le \nu$. The only choice we have is to set
                $$
                    \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} = s^{\ast}_{k_{1}, k_{2}}.
                $$
            With this we get
                $$
                    \max_{p \in K_{p}} \langle Au^{\ast}, p \rangle,
                $$
            and the $\mu_{k_{1}, k_{2}}$ can be chosen arbitrarily. This shows, that the two problems are equivalent.
        \end{enumerate}\qed
    \end{proof}

    Defining the function
    $$
        \mathcal{M}(u, \mu, p, s) = \langle Au, p \rangle + \sum_{k_{1} = 1}^{S} \sum_{k_{2} = 1}^{S} \langle \mu_{k_{1}, k_{2}}, \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} - s_{k_{1}, k_{2}} \rangle
    $$

    leads to

        \begin{eqnarray}
            \frac{\partial \mathcal{M}(u, \mu, p, s)}{\partial u} &=& A^{T} p \\
            \frac{\partial \mathcal{M}(u, \mu, p, s)}{\partial p_{k}} &=& \sum_{k_{1}, k_{2}} \mu_{k_{1}, k_{2}} \\
            \frac{\partial \mathcal{M}(u, \mu, p, s)}{\partial \mu_{k_{1}, k_{2}}} &=& \sum_{k_{1}, k_{2}} \bigg( \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} - s_{k_{1}, k_{2}} \bigg) \\
            \frac{\partial \mathcal{M}(u, \mu, p, s)}{\partial p} &=& Au + \hat{p}.
        \end{eqnarray}

    with

        \begin{eqnarray}
            \frac{\partial \mathcal{M}(u, \mu, p, s)}{\partial p_{l}} &=& (Au)_{l} + \frac{\partial}{\partial p_{l}} \bigg(\sum_{k_{1} = 1}^{S} \sum_{k_{2} = k_{1}}^{S} \langle \mu_{k_{1}, k_{2}}, s_{k_{1}, k_{2}} - \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \bigg) \notag \\
            &=& (Au)_{l} + \frac{\partial}{\partial p_{l}} \bigg(\sum_{k_{1} = 1}^{S} \sum_{k_{2} = k_{1}}^{S} \langle \mu_{k_{1}, k_{2}}, s_{k_{1}, k_{2}} \rangle - \langle \mu_{k_{1}, k_{2}}, \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \bigg) \notag \\
            &=& (Au)_{l} - \frac{\partial}{\partial p_{l}} \bigg(\sum_{k_{1} = 1}^{S} \sum_{k_{2} = k_{1}}^{S} \langle \mu_{k_{1}, k_{2}}, \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \bigg) \notag \\
            &=& (Au)_{l} - 
                \begin{pmatrix}
                    \sum\limits_{k_{1} = 1}^{l} \sum\limits_{k_{2} = k_{1}}^{l} \mu_{k_{1}, k_{2}}^{1} \\
                    \sum\limits_{k_{1} = 1}^{l} \sum\limits_{k_{2} = k_{1}}^{l} \mu_{k_{1}, k_{2}}^{2}
                \end{pmatrix}
        \end{eqnarray}

    With this it follows

        \begin{equation}
            \tilde{p} = -
                \begin{pmatrix}
                    \sum\limits_{k_{1} = 1}^{l} \sum\limits_{k_{2} = k_{1}}^{l} \mu_{k_{1}, k_{2}}^{1} \\
                    \sum\limits_{k_{1} = 1}^{l} \sum\limits_{k_{2} = k_{1}}^{l} \mu_{k_{1}, k_{2}}^{2}
                \end{pmatrix}
        \end{equation}

    We have

        \begin{algorithm}
            Choose $(u^{0}, p^{0}, \mu^{0}, s^{0}) \in C \times K_{p} \times \mathbb{R}^{2 \times N \times M \times S} \times \mathbb{R}^{2 \times N \times M \times S}$ and let $\bar{x}^{0} = u^{0}, \bar{\mu}^{0} = \mu^{0}$. We choose $\tau_{u} = \frac{1}{6}, \tau_{\mu} = \frac{1}{2 + k_{2} - k_{1}}, \sigma_{p} = \frac{1}{3 + S}, \sigma_{s} = 1$. Then, we let for each $n \ge 0$
                \begin{equation}
                    \left\{ 
                        \begin{array}{l l}
                          p^{n+1} = \Pi_{K_{p}} (p^{n} + \sigma_{p} (A \bar{u}^{n} + \tilde{p})) \\
                          s_{k_{1}, k_{2}}^{n+1} = \Pi_{|\cdot| \le \nu} (s_{k_{1}, k_{2}}^{n} + \sigma_{s} \bar{\mu}_{k_{1}, k_{2}}^{n}) \\
                          u^{n+1} = \Pi_{C} (u^{n} - \tau_{u} A^{*} p^{n+1}) \\
                          \mu_{k_{1}, k_{2}}^{n+1} = \mu_{k_{1}, k_{2}}^{n} - \tau_{\mu} (s_{k_{1}, k_{2}}^{n+1} - \sum_{k_{1} \le k \le k_{2}} p^{x}_{k} \\
                          \bar{u}^{n+1} = 2u^{n+1} - u^{n} \\
                          \bar{\mu}_{k_{1}, k_{2}}^{n+1} = 2\mu_{k_{1}, k_{2}}^{n+1} - \mu_{k_{1}, k_{2}}^{n}.
                        \end{array}
                    \right.
                \end{equation}
        \end{algorithm}

% % % chapter an_algorithm_for_minimizing_the_mumford_shah_functional (end)