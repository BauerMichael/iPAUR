\chapter{Total Variation based Image Processing} % (fold)
\label{cha:total_variation_based_image_processing}

    In the first chapter we saw the concept of total variation. From this point on, we assume that our functions $u$ are always smooth enough that we have at least $u \in C^{1}(\Omega)$ or more general $u \in W^{1}_{1}(\Omega)$. We saw in \ref{eq:tvl1} that the total variation can then be expressed by

        \begin{equation}
            \textnormal{TV}(u) = \int_{\Omega} |\nabla\,f| dx.
        \end{equation}

    Since, there exists a couple of models to approximate an input image $g$ by a function $u$, we want to make some conventions about this. Our models are based on the idea that a given image $g$ consists of two things: data and noise. This can be expressed by
        $$
            g = g_{d} + g_{n},
        $$
    where $g_{d}$ denotes the (actual) data of the image and $g_{n}$ the noise which should be removed. %From this starting point, one can derive statistical models to remove the noise effectively, see for instance \cite{Chambolle-et-al-10}.
    %One of these models, which was proposed At the end of this statistical computations you will find a model,
    An example model to efficiently remove Gaussian noise from an image input image $g$ would be the so called ROF model. Before introducing this model in detail, let us state one general property of all our underlying models. What they all have in common is the idea how they are set up:
        $$
            \textnormal{Model} = \textnormal{Data Fidelity Term} + \textnormal{Regularizer Term}.
        $$
    So all of our models look exactly like this. The data fidelity term assures that the approximation $u$ is as close to the input image $g$ as possible. For instance, one can set $G(u) = \frac{1}{2} ||u - g||_{2}^{2}$ having the quadratic, euclidean distance as the data fidelity term. As a quadratic function this term would also be convex. For the regularizer we will see that we find convex terms which are easy to handle, but we also find highly non-convex regularizers like in the Mumford-Shah Functional, discussed in Chapter \ref{cha:an_algorithm_for_minimizing_the_mumford_shah_functional}.

    

% chapter total_variation_based_image_processing (end)